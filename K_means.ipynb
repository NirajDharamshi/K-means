{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "K means.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NirajDharamshi/K-means/blob/master/K_means.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "GK9X3FkK94uT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import calinski_harabaz_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l3iW91g8-2v_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def csr_read(fname, ftype=\"csr\", nidx=1):\n",
        "    r\"\"\" \n",
        "        Read CSR matrix from a text file. \n",
        "        \n",
        "        \\param fname File name for CSR/CLU matrix\n",
        "        \\param ftype Input format. Acceptable formats are:\n",
        "            - csr - Compressed sparse row\n",
        "            - clu - Cluto format, i.e., CSR + header row with \"nrows ncols nnz\"\n",
        "        \\param nidx Indexing type in CSR file. What does numbering of feature IDs start with?\n",
        "    \"\"\"\n",
        "    \n",
        "    with open(fname) as f:\n",
        "        lines = f.readlines()\n",
        "    \n",
        "    if ftype == \"clu\":\n",
        "        p = lines[0].split()\n",
        "        nrows = int(p[0])\n",
        "        ncols = int(p[1])\n",
        "        nnz = long(p[2])\n",
        "        lines = lines[1:]\n",
        "        assert(len(lines) == nrows)\n",
        "    elif ftype == \"csr\":\n",
        "        nrows = len(lines)\n",
        "        ncols = 0 \n",
        "        nnz = 0 \n",
        "        for i in range(nrows):\n",
        "            p = lines[i].split()\n",
        "            if len(p) % 2 != 0:\n",
        "                raise ValueError(\"Invalid CSR matrix. Row %d contains %d numbers.\" % (i, len(p)))\n",
        "            nnz += len(p)/2\n",
        "            for j in range(0, len(p), 2): \n",
        "                cid = int(p[j]) - nidx\n",
        "                if cid+1 > ncols:\n",
        "                    ncols = cid+1\n",
        "    else:\n",
        "        raise ValueError(\"Invalid sparse matrix ftype '%s'.\" % ftype)\n",
        "    nnz=int(nnz)\n",
        "    val = np.zeros(nnz, dtype=np.float)\n",
        "    ind = np.zeros(nnz, dtype=np.int)\n",
        "    ptr = np.zeros(nrows+1, dtype=np.long)\n",
        "    n = 0 \n",
        "    for i in range(nrows):\n",
        "        p = lines[i].split()\n",
        "        for j in range(0, len(p), 2): \n",
        "            ind[n] = int(p[j]) - nidx\n",
        "            val[n] = float(p[j+1])\n",
        "            n += 1\n",
        "        ptr[i+1] = n \n",
        "    \n",
        "    assert(n == nnz)\n",
        "    \n",
        "    return csr_matrix((val, ind, ptr), shape=(nrows, ncols), dtype=np.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PdPX4jNb_Ofk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def csr_idf(matrix, copy=False, **kargs):\n",
        "    r\"\"\" Scale a CSR matrix by idf. \n",
        "    Returns scaling factors as dict. If copy is True, \n",
        "    returns scaled matrix and scaling factors.\n",
        "    \"\"\"\n",
        "    if copy is True:\n",
        "        matrix = matrix.copy()\n",
        "    nrows = matrix.shape[0]\n",
        "    nnz = matrix.nnz\n",
        "    ind, val, ptr = matrix.indices, matrix.data, matrix.indptr\n",
        "    # document frequency\n",
        "    df = defaultdict(int)\n",
        "    for i in ind:\n",
        "        df[i] += 1\n",
        "    # inverse document frequency\n",
        "    for k,v in df.items():\n",
        "        df[k] = np.log(nrows / float(v))  ## df turns to idf - reusing memory\n",
        "    # scale by idf\n",
        "    for i in range(0, nnz):\n",
        "        val[i] *= df[ind[i]]\n",
        "        \n",
        "    return df if copy is False else matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l6cmbIMp_Tfk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def csr_l2normalize(matrix, copy=False, **kargs):\n",
        "    r\"\"\" Normalize the rows of a CSR matrix by their L-2 norm. \n",
        "    If copy is True, returns a copy of the normalized matrix.\n",
        "    \"\"\"\n",
        "    if copy is True:\n",
        "        matrix = matrix.copy()\n",
        "    nrows = matrix.shape[0]\n",
        "    nnz = matrix.nnz\n",
        "    ind, val, ptr = matrix.indices, matrix.data, matrix.indptr\n",
        "    # normalize\n",
        "    for i in range(nrows):\n",
        "        rsum = 0.0    \n",
        "        for j in range(ptr[i], ptr[i+1]):\n",
        "            rsum += val[j]**2\n",
        "        if rsum == 0.0:\n",
        "            continue  # do not normalize empty rows\n",
        "        rsum = float(1.0/np.sqrt(rsum))\n",
        "        for j in range(ptr[i], ptr[i+1]):\n",
        "            val[j] *= rsum\n",
        "            \n",
        "    if copy is True:\n",
        "        return matrix\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nj_a3Xjw_Vci",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def initialCentroids(matrix):\n",
        "    matrixShuffled = shuffle(matrix, random_state=0)\n",
        "    return matrixShuffled[:2,:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iyCX6iM6_YGz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def similarity(matrix, centroids):\n",
        "    similarities = matrix.dot(centroids.T)\n",
        "    return similarities\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ttsBZ0Fo_aFC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def findClusters(matrix, centroids):\n",
        "    \n",
        "    clusterA = list()\n",
        "    clusterB = list()\n",
        "    \n",
        "    similarityMatrix = similarity(matrix, centroids)\n",
        "    \n",
        "    for index in range(similarityMatrix.shape[0]):\n",
        "        similarityRow = similarityMatrix[index]\n",
        "        \n",
        "        #Sort the index of the matrix in ascending order of value and get the index of the last element\n",
        "        #This index will be the cluster that the row in input matrix will belong to\n",
        "        similaritySorted = np.argsort(similarityRow)[-1]\n",
        "        \n",
        "        if similaritySorted == 0:\n",
        "            clusterA.append(index)\n",
        "        else:\n",
        "            clusterB.append(index)\n",
        "        \n",
        "    return clusterA, clusterB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u3dezzIu_b1u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def recalculateCentroid(matrix, clusters):\n",
        "    centroids = list()\n",
        "    \n",
        "    for i in range(0,2):\n",
        "        cluster = matrix[clusters[i],:]\n",
        "        clusterMean = cluster.mean(0)\n",
        "        centroids.append(clusterMean)\n",
        "        \n",
        "    centroids_array = np.asarray(centroids)\n",
        "    \n",
        "    return centroids_array\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cqrorAVq_d3L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def kmeans(matrix, numberOfIterations):\n",
        "    \n",
        "    centroids = initialCentroids(matrix)\n",
        "    \n",
        "    for _ in range(numberOfIterations):\n",
        "        \n",
        "        clusters = list()\n",
        "        \n",
        "        clusterA, clusterB = findClusters(matrix, centroids)\n",
        "        \n",
        "        if len(clusterA) > 1:\n",
        "            clusters.append(clusterA)\n",
        "        if len(clusterB) > 1:\n",
        "            clusters.append(clusterB)\n",
        "            \n",
        "        centroids = recalculateCentroid(matrix, clusters)\n",
        "        \n",
        "    return clusterA, clusterB\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OxOkIeY9_fuW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def calculateSSE(matrix, clusters):\n",
        "    \n",
        "    SSE_list = list()\n",
        "    SSE_array = []\n",
        "    \n",
        "    for cluster in clusters:\n",
        "        members = matrix[cluster,:]\n",
        "        SSE = np.sum(np.square(members - np.mean(members)))\n",
        "        SSE_list.append(SSE)\n",
        "        \n",
        "    SSE_array = np.asarray(SSE_list)\n",
        "    dropClusterIndex = np.argsort(SSE_array)[-1]\n",
        "            \n",
        "    return dropClusterIndex\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nSHiq4lA_hsG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def bisecting_kmeans(matrix, k, numberOfIterations):\n",
        "    \n",
        "    clusters = list()\n",
        "    \n",
        "    initialcluster = list()\n",
        "    for i in range(matrix.shape[0]):\n",
        "        initialcluster.append(i)\n",
        "    \n",
        "    clusters.append(initialcluster)\n",
        "    \n",
        "    while len(clusters) < k:\n",
        "\n",
        "        dropClusterIndex = calculateSSE(matrix, clusters)\n",
        "        droppedCluster = clusters[dropClusterIndex]\n",
        "        \n",
        "        clusterA, clusterB = kmeans(matrix[droppedCluster,:], numberOfIterations)\n",
        "        del clusters[dropClusterIndex]\n",
        "        \n",
        "        actualClusterA = list()\n",
        "        actualClusterB = list()\n",
        "        for index in clusterA:\n",
        "            actualClusterA.append(droppedCluster[index])\n",
        "            \n",
        "        for index in clusterB:\n",
        "            actualClusterB.append(droppedCluster[index])\n",
        "        \n",
        "        clusters.append(actualClusterA)\n",
        "        clusters.append(actualClusterB)\n",
        "    \n",
        "    labels = [0] * matrix.shape[0]\n",
        "\n",
        "    for index, cluster in enumerate(clusters):\n",
        "        for idx in cluster:\n",
        "            labels[idx] = index + 1\n",
        "    return labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2DywYU9I_kMs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#Read CSR matrix from the input file\n",
        "csrMatrix = csr_read('train.dat', ftype=\"csr\", nidx=1)\n",
        "\n",
        "#Scale the CSR matrix by idf (Inverse Document Frequency)\n",
        "csrIDF = csr_idf(csrMatrix, copy=True)\n",
        "\n",
        "#Normalize the rows of a CSR matrix by their L-2 norm.\n",
        "csrL2Normalized = csr_l2normalize(csrIDF, copy=True)\n",
        "\n",
        "#Obtain a dense ndarray representation of the CSR matrix.\n",
        "denseMatrix = csrL2Normalized.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K3MappeT_m09",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "kValues = list()\n",
        "scores = list()\n",
        "\n",
        "for k in range(3, 22, 2):\n",
        "    labels = bisecting_kmeans(denseMatrix, k, 10)\n",
        "    \n",
        "    if (k == 7):\n",
        "        # write result to output file\n",
        "        outputFile = open(\"output.dat\", \"w\")\n",
        "        for index in labels:\n",
        "            outputFile.write(str(index) +'\\n')\n",
        "        outputFile.close()\n",
        "\n",
        "    score = calinski_harabaz_score(denseMatrix, labels)\n",
        "    kValues.append(k)\n",
        "    scores.append(score)\n",
        "    \n",
        "    print (\"For K= %d Calinski Harabaz Score is %f\" %(k, score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wzaFjTRBABTa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}